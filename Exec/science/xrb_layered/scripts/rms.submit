#!/bin/bash
#SBATCH --account=m3018
#SBATCH --constraint=cpu
#SBATCH --output=slurm.rmsparallel.%j.out
#SBATCH --nodes=1
#SBATCH --time=01:00:00
#SBATCH --qos=regular
###SBATCH --time=00:05:00
###SBATCH --qos=debug
###SBATCH --mail-type=all
###SBATCH --mail-user=simon.guichandut@mail.mcgill.ca

# Run directory
RUN_DIR=$1
echo $RUN_DIR

# List of variables to rms
VARS="vely"

PLOT_DIR=PLOTS
PLOT_BASENAME="*xrb_0"

script=$xrb/scripts/rms_vars.sh

cd $RUN_DIR

# Find all plotfiles that do not already have a rms
plots=()
for plotfile in $PLOT_DIR/$PLOT_BASENAME*; do
    [[ ! -d "$plotfile" ]] && continue
    [[ "$plotfile" == *.old.* ]] && continue
    [[ -e "$plotfile/rms" ]] && continue
    plots+=($plotfile)
done

N0=${#plots[@]}
echo $N0" plotfiles to process"

if [ $N0 -eq 0 ]; then
    exit 0
fi

# If this is being run in a slurm job, do parallel
# Otherwise, loop through the plotfiles one by one

if [ -n "$SLURM_JOB_ID" ]; then

    module load parallel
    NTASK=32

    echo "Running in parallel with "$NTASK" processes"

    # Temporary text file with all of the plotfiles
    tmpfile=$(mktemp)
    printf "%s\n" "${plots[@]}" > "$tmpfile"
    
    # Use srun parallel as in the "Running Many Tasks Inside a Single Node Allocation" example here
    # https://docs.nersc.gov/jobs/workflow/gnuparallel/
    srun parallel --jobs $NTASK "$script {} \"$VARS\"" :::: "$tmpfile"
    #parallel --jobs $NTASK "$script {} \"$VARS\"" :::: "$tmpfile"
    
    rm -f "$tmpfile"
    
else

    for ((i=0; i<$N0; i++)); do
        plotfile="${plots[$i]}"
        #echo "Processing: $plotfile"
        $script "$plotfile" $VARS
    
        # Print the number of remaining plotfiles
        remaining=$((N0 - i - 1))
        echo $remaining
    done

fi

echo "done"
